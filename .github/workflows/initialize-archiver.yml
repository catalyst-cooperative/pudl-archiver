---
name: initialize-archiver

on:
  workflow_dispatch:
    inputs:
      datasets:
        description: 'Comma-separated list of datasets to archive (e.g., "ferc2","ferc6").'
        default: ""
        required: true
        type: string
      server:
        description: "Which Zenodo server would you like to run on?"
        default: "sandbox"
        options:
          - sandbox
          - production
        required: true
        type: choice

jobs:
  archive-run:
    defaults:
      run:
        shell: bash -l {0}
    strategy:
      matrix:
        # Note that we can't pass global env variables to the matrix, so we manually reproduce the list of datasets here.
        dataset: ${{ fromJSON(format('[{0}]', inputs.datasets || '' )) }}
      fail-fast: false
    runs-on: ubuntu-latest
    permissions:
      contents: "read"
      id-token: "write"
    steps:
      - uses: actions/checkout@v6

      - name: Set default GCP credentials
        id: gcloud-auth
        continue-on-error: true
        uses: "google-github-actions/auth@v3"
        with:
          workload_identity_provider: "projects/345950277072/locations/global/workloadIdentityPools/gh-actions-pool/providers/gh-actions-provider"
          service_account: "pudl-sources@catalyst-cooperative-pudl.iam.gserviceaccount.com"

      - name: Set up pixi
        uses: prefix-dev/setup-pixi@v0.9.4

      - name: Log the pixi environment
        run: |
          pixi info
          pixi list

      - name: Additional Playwright setup
        run: |
          pixi run playwright install --with-deps webkit
          pixi run playwright install --with-deps chromium

      - name: Initialize production archive for ${{ matrix.dataset }}
        env:
          EPACEMS_API_KEY: ${{ secrets.EPACEMS_API_KEY }}
          ZENODO_TOKEN_UPLOAD: ${{ secrets.ZENODO_TOKEN_UPLOAD }}
          ZENODO_TOKEN_PUBLISH: ${{ secrets.ZENODO_TOKEN_PUBLISH }}
        if: ${{ inputs.server == 'production' }}
        run: |
          pixi run pudl_archiver archive zenodo ${{ matrix.dataset }} --initialize --clobber-unchanged

      - name: Initialize sandbox archive for ${{ matrix.dataset }}
        env:
          ZENODO_SANDBOX_TOKEN_UPLOAD: ${{ secrets.ZENODO_SANDBOX_TOKEN_UPLOAD }}
          ZENODO_SANDBOX_TOKEN_PUBLISH: ${{ secrets.ZENODO_SANDBOX_TOKEN_PUBLISH }}
          EPACEMS_API_KEY: ${{ secrets.EPACEMS_API_KEY }}
        if: ${{ inputs.server == 'sandbox' }}
        run: |
          pixi run pudl_archiver archive zenodo ${{ matrix.dataset }} --initialize --sandbox  --clobber-unchanged

      - name: Upload run summaries
        if: always()
        id: upload_summaries
        uses: actions/upload-artifact@v6
        with:
          name: run-summaries-${{ matrix.dataset }}
          path: ${{ matrix.dataset }}_run_summary.json

  archive-notify:
    runs-on: ubuntu-latest
    needs:
      - archive-run
    if: ${{ always() }}
    steps:
      - uses: actions/checkout@v6
      - name: Download summaries
        id: download
        uses: actions/download-artifact@v7
        with:
          pattern: run-summaries-*
          merge-multiple: true
      - name: show summaries
        run: ls -R
      - name: Munge summaries together
        id: all_summaries
        run: |
          {
            echo "SLACK_PAYLOAD<<EOF"
            ./scripts/make_slack_notification_message.py --summary-files *_run_summary.json | tee slack-payload.json
            echo "EOF"
          } >> "$GITHUB_OUTPUT"
      - name: Post update to pudl-deployment
        uses: slackapi/slack-github-action@v2.1.1
        with:
          method: chat.postMessage
          token: ${{ secrets.PUDL_DEPLOY_SLACK_TOKEN }}
          payload: |
            text: "Created new archiver(s)."
            blocks: ${{ steps.all_summaries.outputs.SLACK_PAYLOAD }}
            channel: "C03FHB9N0PQ"
